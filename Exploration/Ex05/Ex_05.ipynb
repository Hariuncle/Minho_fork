{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f3c2843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.3\n",
      "0.5.2\n",
      "4.1.2\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import konlpy\n",
    "import gensim\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "print(pandas.__version__)\n",
    "print(konlpy.__version__)\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a2f9104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c8c68c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    \"\"\"\n",
    "    train_data, test_data: pandas DataFrame\n",
    "        - 'document': 텍스트 스트링\n",
    "        - 'label': 해당 텍스트의 레이블\n",
    "    num_words: 사용할 단어 수 (사전 구성 시 가장 빈번한 num_words-1 단어를 사용하고,\n",
    "               index 0은 OOV(Out-Of-Vocabulary) 용으로 사용)\n",
    "    \"\"\"\n",
    "    # 1. 중복 데이터와 NaN(결측치) 제거 (텍스트와 레이블 모두 확인)\n",
    "    train_data = train_data.drop_duplicates().dropna(subset=['document', 'label'])\n",
    "    test_data = test_data.drop_duplicates().dropna(subset=['document', 'label'])\n",
    "    \n",
    "    # 2. 한국어 토크나이저(Mecab)를 이용하여 토큰화하고 불용어 제거\n",
    "    def tokenize(text):\n",
    "        # 형태소 단위의 토큰 추출 (morphs 사용)\n",
    "        tokens = tokenizer.morphs(text)\n",
    "        # 불용어 제거\n",
    "        tokens = [token for token in tokens if token not in stopwords]\n",
    "        return tokens\n",
    "\n",
    "    # 새 컬럼 'tokens'에 토큰화 결과 저장\n",
    "    train_data['tokens'] = train_data['document'].apply(tokenize)\n",
    "    test_data['tokens'] = test_data['document'].apply(tokenize)\n",
    "    \n",
    "    # 3. 사전(word_to_index) 구성: train 데이터에 나타난 모든 토큰의 빈도수 기반\n",
    "    all_tokens = [token for tokens in train_data['tokens'] for token in tokens]\n",
    "    counter = Counter(all_tokens)\n",
    "    # num_words-1개 단어를 선택 (인덱스 0은 OOV 용으로 예약)\n",
    "    most_common = counter.most_common(num_words - 1)\n",
    "    word_to_index = {word: idx + 1 for idx, (word, _) in enumerate(most_common)}\n",
    "    \n",
    "    # 4. 각 텍스트(토큰 리스트)를 사전 인덱스 스트링으로 변환\n",
    "    def tokens_to_indices(tokens):\n",
    "        # 토큰이 사전에 없으면 0 (OOV)으로 처리\n",
    "        return [word_to_index.get(token, 0) for token in tokens]\n",
    "    \n",
    "    X_train = train_data['tokens'].apply(tokens_to_indices).tolist()\n",
    "    y_train = train_data['label'].tolist()\n",
    "    X_test = test_data['tokens'].apply(tokens_to_indices).tolist()\n",
    "    y_test = test_data['label'].tolist()\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, word_to_index\n",
    "    \n",
    "x_train, y_train, x_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "533a27f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12558176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa2ca058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 리뷰 (인덱스 리스트): [29, 71, 918, 1, 1, 36, 227, 17, 30, 749]\n",
      "첫번째 리뷰 라벨: 0\n",
      "1번째 리뷰 문장 길이: 10\n",
      "2번째 리뷰 문장 길이: 17\n",
      "\n",
      "예시 - index_to_word[1]: .\n",
      "\n",
      "디코딩된 첫번째 리뷰:\n",
      "더 빙 . . 진짜 짜증 나 네요 목소리\n",
      "\n",
      "문장 길이 통계:\n",
      "문장 길이 평균    : 15.65940637625505\n",
      "문장 길이 최대    : 116\n",
      "문장 길이 표준편차: 12.859527414389605\n",
      "\n",
      "pad_sequences의 maxlen: 41\n",
      "전체 문장의 93.58%가 maxlen (41) 이내에 포함됩니다.\n",
      "\n",
      "패딩 적용 후:\n",
      "Padded x_train shape: (149995, 41)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# ============================================================================\n",
    "# 1. 리뷰 데이터 및 문장 길이 확인\n",
    "# ============================================================================\n",
    "# 예시: x_train은 단어 인덱스 리스트의 리스트, y_train은 해당 라벨 리스트\n",
    "print(\"첫번째 리뷰 (인덱스 리스트):\", x_train[0])\n",
    "print(\"첫번째 리뷰 라벨:\", y_train[0])\n",
    "print(\"1번째 리뷰 문장 길이:\", len(x_train[0]))\n",
    "print(\"2번째 리뷰 문장 길이:\", len(x_train[1]))\n",
    "\n",
    "# 사전 매핑 확인\n",
    "print(\"\\n예시 - index_to_word[1]:\", index_to_word.get(1))  # index 1에 해당하는 단어 출력\n",
    "\n",
    "# 첫번째 리뷰 디코딩 결과 출력\n",
    "print(\"\\n디코딩된 첫번째 리뷰:\")\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "\n",
    "# ============================================================================\n",
    "# 2. 문장 길이 분포 분석 및 적절한 최대 문장 길이(maxlen) 지정\n",
    "# ============================================================================\n",
    "# 학습과 테스트 데이터를 모두 합쳐 문장 길이 분포를 분석합니다.\n",
    "total_data = list(x_train) + list(x_test)\n",
    "num_tokens = np.array([len(tokens) for tokens in total_data])\n",
    "\n",
    "print(\"\\n문장 길이 통계:\")\n",
    "print(\"문장 길이 평균    :\", np.mean(num_tokens))\n",
    "print(\"문장 길이 최대    :\", np.max(num_tokens))\n",
    "print(\"문장 길이 표준편차:\", np.std(num_tokens))\n",
    "\n",
    "# 예시: 최대 길이를 (평균 + 2×표준편차)로 설정\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print(\"\\npad_sequences의 maxlen:\", maxlen)\n",
    "\n",
    "percentage = np.sum(num_tokens < max_tokens) / len(num_tokens) * 100\n",
    "print(f\"전체 문장의 {percentage:.2f}%가 maxlen ({maxlen}) 이내에 포함됩니다.\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. keras.preprocessing.sequence.pad_sequences 를 활용한 패딩 추가\n",
    "# ============================================================================\n",
    "# 패딩에 사용할 값은 보통 '<PAD>' 토큰에 해당하는 인덱스입니다.\n",
    "# 만약 load_data()에서 '<PAD>' 토큰을 지정하지 않았다면, 기본값 0을 사용합니다.\n",
    "pad_value = word_to_index.get(\"<PAD>\", 0)\n",
    "\n",
    "# 여기서는 post-padding(문장 뒤쪽에 패딩 추가)을 예시로 합니다.\n",
    "x_train_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    x_train,\n",
    "    value=pad_value,\n",
    "    padding='post',  # 'pre'를 선택하면 앞쪽에 패딩 추가\n",
    "    maxlen=maxlen\n",
    ")\n",
    "\n",
    "x_test_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    x_test,\n",
    "    value=pad_value,\n",
    "    padding='post',\n",
    "    maxlen=maxlen\n",
    ")\n",
    "\n",
    "print(\"\\n패딩 적용 후:\")\n",
    "print(\"Padded x_train shape:\", x_train_padded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9378a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:1970: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial_x_train shape: (139995,)\n",
      "partial_y_train shape: (139995,)\n",
      "\n",
      "=== LSTM 기반 모델 ===\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 41, 16)            160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "=== 1D CNN 모델 ===\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 41, 16)            160000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 35, 32)            3616      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 163,889\n",
      "Trainable params: 163,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "=== Bidirectional LSTM 모델 ===\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 41, 16)            160000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 16)                1600      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 161,745\n",
      "Trainable params: 161,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 1. Validation set 구성\n",
    "# --------------------------------------------------------------------\n",
    "# 예시: 전체 x_train, y_train 중 처음 10000건을 validation set으로 분리\n",
    "x_val = x_train[:10000]\n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 데이터\n",
    "partial_x_train = x_train[10000:]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(\"partial_x_train shape:\", np.shape(partial_x_train))\n",
    "print(\"partial_y_train shape:\", np.shape(partial_y_train))\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 2. 모델 구성\n",
    "# --------------------------------------------------------------------\n",
    "# 공통 하이퍼파라미터\n",
    "vocab_size = 10000       # 어휘 사전 크기 (예: 10,000 단어)\n",
    "word_vector_dim = 16     # 임베딩(워드 벡터) 차원\n",
    "# maxlen: pad_sequences()를 통해 지정한 최대 문장 길이 (예시: 이미 정의되어 있다고 가정)\n",
    "\n",
    "# --------------------------\n",
    "# 모델 1: LSTM 기반 모델\n",
    "# --------------------------\n",
    "model_lstm = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_length=maxlen),\n",
    "    tf.keras.layers.LSTM(8),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # 이진 분류: sigmoid 사용\n",
    "])\n",
    "print(\"\\n=== LSTM 기반 모델 ===\")\n",
    "model_lstm.summary()\n",
    "\n",
    "# --------------------------\n",
    "# 모델 2: 1D CNN 모델\n",
    "# --------------------------\n",
    "model_cnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_length=maxlen),\n",
    "    # 1D convolution: 필터 수 32, 커널 사이즈 7\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=7, activation='relu'),\n",
    "    # 전체 시퀀스에 대해 최대값을 취함\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "print(\"\\n=== 1D CNN 모델 ===\")\n",
    "model_cnn.summary()\n",
    "\n",
    "# --------------------------\n",
    "# 모델 3: Bidirectional LSTM 모델\n",
    "# --------------------------\n",
    "model_bi_lstm = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_length=maxlen),\n",
    "    # 양방향 LSTM: 양쪽 방향의 정보를 모두 고려\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8)),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "print(\"\\n=== Bidirectional LSTM 모델 ===\")\n",
    "model_bi_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac3448ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LSTM 기반 모델 학습 시작 ===\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 3s 6ms/step - loss: 0.2376 - accuracy: 0.8910 - val_loss: 0.4021 - val_accuracy: 0.8456\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.2305 - accuracy: 0.8937 - val_loss: 0.4269 - val_accuracy: 0.8430\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.2257 - accuracy: 0.8960 - val_loss: 0.4291 - val_accuracy: 0.8452\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.2209 - accuracy: 0.8974 - val_loss: 0.4579 - val_accuracy: 0.8485\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.2174 - accuracy: 0.8982 - val_loss: 0.4401 - val_accuracy: 0.8467\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.2136 - accuracy: 0.8996 - val_loss: 0.4664 - val_accuracy: 0.8407\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.2096 - accuracy: 0.9020 - val_loss: 0.4648 - val_accuracy: 0.8451\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.2064 - accuracy: 0.9031 - val_loss: 0.4604 - val_accuracy: 0.8347\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.2044 - accuracy: 0.9034 - val_loss: 0.4696 - val_accuracy: 0.8339\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 1s 5ms/step - loss: 0.2002 - accuracy: 0.9044 - val_loss: 0.4789 - val_accuracy: 0.8344\n",
      "\n",
      "LSTM 모델 학습 완료.\n",
      "\n",
      "=== 1D CNN 모델 학습 시작 ===\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 3s 5ms/step - loss: 0.4940 - accuracy: 0.7592 - val_loss: 0.3498 - val_accuracy: 0.8460\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 0.3252 - accuracy: 0.8629 - val_loss: 0.3325 - val_accuracy: 0.8577\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 0.2925 - accuracy: 0.8792 - val_loss: 0.3300 - val_accuracy: 0.8567\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 0.2689 - accuracy: 0.8913 - val_loss: 0.3326 - val_accuracy: 0.8564\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 0.2466 - accuracy: 0.9026 - val_loss: 0.3390 - val_accuracy: 0.8548\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 0.2239 - accuracy: 0.9136 - val_loss: 0.3565 - val_accuracy: 0.8524\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 0.2010 - accuracy: 0.9243 - val_loss: 0.3738 - val_accuracy: 0.8490\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 0.1791 - accuracy: 0.9344 - val_loss: 0.3981 - val_accuracy: 0.8482\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 0.1581 - accuracy: 0.9438 - val_loss: 0.4285 - val_accuracy: 0.8450\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 1s 4ms/step - loss: 0.1392 - accuracy: 0.9516 - val_loss: 0.4634 - val_accuracy: 0.8454\n",
      "\n",
      "1D CNN 모델 학습 완료.\n",
      "\n",
      "=== Bidirectional LSTM 모델 학습 시작 ===\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 5s 9ms/step - loss: 0.4692 - accuracy: 0.7880 - val_loss: 0.3568 - val_accuracy: 0.8445\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 0.3397 - accuracy: 0.8563 - val_loss: 0.3476 - val_accuracy: 0.8504\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 0.3207 - accuracy: 0.8658 - val_loss: 0.3498 - val_accuracy: 0.8490\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 0.3104 - accuracy: 0.8703 - val_loss: 0.3483 - val_accuracy: 0.8501\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 0.3021 - accuracy: 0.8746 - val_loss: 0.3480 - val_accuracy: 0.8474\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 0.2929 - accuracy: 0.8788 - val_loss: 0.3480 - val_accuracy: 0.8475\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 0.2837 - accuracy: 0.8833 - val_loss: 0.3437 - val_accuracy: 0.8517\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 0.2744 - accuracy: 0.8872 - val_loss: 0.3477 - val_accuracy: 0.8512\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 0.2654 - accuracy: 0.8914 - val_loss: 0.3450 - val_accuracy: 0.8547\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 2s 7ms/step - loss: 0.2553 - accuracy: 0.8962 - val_loss: 0.3509 - val_accuracy: 0.8525\n",
      "\n",
      "Bidirectional LSTM 모델 학습 완료.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. 학습 데이터와 검증 데이터에 대해 패딩 적용 및 라벨 데이터 NumPy 배열 변환\n",
    "# -----------------------------------------------------------------------------\n",
    "# pad_sequences를 통해 모든 입력 시퀀스의 길이를 maxlen으로 맞춥니다.\n",
    "# pad_value는 '<PAD>' 토큰에 해당하는 인덱스 (정의되어 있지 않다면 기본값 0 사용)\n",
    "pad_value = word_to_index.get(\"<PAD>\", 0)\n",
    "\n",
    "partial_x_train_padded = pad_sequences(partial_x_train,\n",
    "                                       value=pad_value,\n",
    "                                       padding='post',   # 또는 'pre'\n",
    "                                       maxlen=maxlen)\n",
    "x_val_padded = pad_sequences(x_val,\n",
    "                             value=pad_value,\n",
    "                             padding='post',    # 또는 'pre'\n",
    "                             maxlen=maxlen)\n",
    "\n",
    "# 라벨 데이터를 리스트에서 NumPy 배열로 변환합니다.\n",
    "partial_y_train = np.array(partial_y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. 모델 학습 시작\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# ---------------------------\n",
    "# 모델 1: LSTM 기반 모델\n",
    "# ---------------------------\n",
    "print(\"=== LSTM 기반 모델 학습 시작 ===\")\n",
    "model_lstm.compile(optimizer='adam',\n",
    "                   loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "history_lstm = model_lstm.fit(partial_x_train_padded, partial_y_train,\n",
    "                              epochs=10,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(x_val_padded, y_val))\n",
    "print(\"\\nLSTM 모델 학습 완료.\\n\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 모델 2: 1D CNN 모델\n",
    "# ---------------------------\n",
    "print(\"=== 1D CNN 모델 학습 시작 ===\")\n",
    "model_cnn.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history_cnn = model_cnn.fit(partial_x_train_padded, partial_y_train,\n",
    "                            epochs=10,\n",
    "                            batch_size=512,\n",
    "                            validation_data=(x_val_padded, y_val))\n",
    "print(\"\\n1D CNN 모델 학습 완료.\\n\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 모델 3: Bidirectional LSTM 모델\n",
    "# ---------------------------\n",
    "print(\"=== Bidirectional LSTM 모델 학습 시작 ===\")\n",
    "model_bi_lstm.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "history_bi_lstm = model_bi_lstm.fit(partial_x_train_padded, partial_y_train,\n",
    "                                    epochs=10,\n",
    "                                    batch_size=512,\n",
    "                                    validation_data=(x_val_padded, y_val))\n",
    "print(\"\\nBidirectional LSTM 모델 학습 완료.\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "232384f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 행렬의 shape: (10000, 16)\n",
      "'사랑'와(과) 유사한 단어:\n",
      "나와라 (유사도: 0.9650)\n",
      "으니깐 (유사도: 0.9433)\n",
      "이래서 (유사도: 0.9322)\n",
      "감사 (유사도: 0.9321)\n",
      "어벤져스 (유사도: 0.9292)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# =============================================================================\n",
    "# 1. 임베딩 행렬 추출\n",
    "# =============================================================================\n",
    "# model_lstm의 첫 번째 레이어가 Embedding 레이어라고 가정합니다.\n",
    "embedding_layer = model_lstm.layers[0]\n",
    "# 임베딩 행렬: shape = (vocab_size, word_vector_dim)\n",
    "embedding_weights = embedding_layer.get_weights()[0]\n",
    "print(\"임베딩 행렬의 shape:\", embedding_weights.shape)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. 코사인 유사도를 활용한 유사 단어 탐색\n",
    "# =============================================================================\n",
    "def find_similar_words(target_word, top_k=5):\n",
    "    \"\"\"\n",
    "    target_word와 유사한 단어를 코사인 유사도를 이용해 찾습니다.\n",
    "    :param target_word: 분석할 단어 (str)\n",
    "    :param top_k: 상위 몇 개 단어를 반환할지\n",
    "    \"\"\"\n",
    "    # target_word가 단어 사전에 존재하는지 확인합니다.\n",
    "    if target_word not in word_to_index:\n",
    "        print(f\"단어 '{target_word}'가 단어 사전에 없습니다.\")\n",
    "        return\n",
    "\n",
    "    target_idx = word_to_index[target_word]\n",
    "    target_vector = embedding_weights[target_idx].reshape(1, -1)\n",
    "    \n",
    "    # 전체 임베딩 행렬과 target_vector 간의 코사인 유사도를 계산합니다.\n",
    "    similarities = cosine_similarity(embedding_weights, target_vector).flatten()\n",
    "    \n",
    "    # 자기 자신은 제외하고 유사도가 높은 단어 상위 top_k개를 찾습니다.\n",
    "    similar_indices = np.argsort(similarities)[::-1][1:top_k+1]\n",
    "    \n",
    "    print(f\"'{target_word}'와(과) 유사한 단어:\")\n",
    "    for idx in similar_indices:\n",
    "        similar_word = index_to_word.get(idx, \"?\")\n",
    "        print(f\"{similar_word} (유사도: {similarities[idx]:.4f})\")\n",
    "\n",
    "# 예시: '영화'와 유사한 단어 5개 출력 (사전에 '영화'가 존재해야 합니다.)\n",
    "find_similar_words(\"사랑\", top_k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d290a8",
   "metadata": {},
   "source": [
    "### 정확도 실험: 양뱡향 LSTM 모델 구조 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4c4f3a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일을 찾았습니다: /aiffel/data/word2vec_ko.model\n",
      "Word2Vec embedding dimension: 100\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 41, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 41, 100)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 41, 128)           84480     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 41, 128)           512       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 41, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,128,705\n",
      "Trainable params: 128,257\n",
      "Non-trainable params: 1,000,448\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "274/274 [==============================] - 11s 22ms/step - loss: 0.5978 - accuracy: 0.6849 - val_loss: 0.4670 - val_accuracy: 0.7784\n",
      "Epoch 2/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.4774 - accuracy: 0.7717 - val_loss: 0.4292 - val_accuracy: 0.8051\n",
      "Epoch 3/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.4396 - accuracy: 0.7947 - val_loss: 0.3934 - val_accuracy: 0.8190\n",
      "Epoch 4/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.4160 - accuracy: 0.8079 - val_loss: 0.3746 - val_accuracy: 0.8317\n",
      "Epoch 5/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.3996 - accuracy: 0.8180 - val_loss: 0.3720 - val_accuracy: 0.8339\n",
      "Epoch 6/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.3869 - accuracy: 0.8233 - val_loss: 0.3645 - val_accuracy: 0.8349\n",
      "Epoch 7/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.3761 - accuracy: 0.8297 - val_loss: 0.3655 - val_accuracy: 0.8420\n",
      "Epoch 8/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.3693 - accuracy: 0.8325 - val_loss: 0.3480 - val_accuracy: 0.8413\n",
      "Epoch 9/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.3599 - accuracy: 0.8387 - val_loss: 0.3563 - val_accuracy: 0.8461\n",
      "Epoch 10/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.3526 - accuracy: 0.8432 - val_loss: 0.3437 - val_accuracy: 0.8490\n",
      "Epoch 11/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.3462 - accuracy: 0.8459 - val_loss: 0.3449 - val_accuracy: 0.8486\n",
      "Epoch 12/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.3417 - accuracy: 0.8486 - val_loss: 0.3403 - val_accuracy: 0.8511\n",
      "Epoch 13/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.3389 - accuracy: 0.8489 - val_loss: 0.3397 - val_accuracy: 0.8473\n",
      "Epoch 14/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.3323 - accuracy: 0.8530 - val_loss: 0.3360 - val_accuracy: 0.8527\n",
      "Epoch 15/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.3285 - accuracy: 0.8540 - val_loss: 0.3340 - val_accuracy: 0.8539\n",
      "Epoch 16/20\n",
      "274/274 [==============================] - 5s 19ms/step - loss: 0.3244 - accuracy: 0.8577 - val_loss: 0.3320 - val_accuracy: 0.8559\n",
      "Epoch 17/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.3223 - accuracy: 0.8576 - val_loss: 0.3258 - val_accuracy: 0.8570\n",
      "Epoch 18/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.3184 - accuracy: 0.8595 - val_loss: 0.3346 - val_accuracy: 0.8557\n",
      "Epoch 19/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.3159 - accuracy: 0.8620 - val_loss: 0.3301 - val_accuracy: 0.8566\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 20/20\n",
      "274/274 [==============================] - 5s 18ms/step - loss: 0.3076 - accuracy: 0.8653 - val_loss: 0.3291 - val_accuracy: 0.8575\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Word2Vec 모델 불러오기 (리눅스 홈 디렉토리의 data 폴더)\n",
    "# =============================================================================\n",
    "word2vec_model_path = os.path.expanduser(\"~/data/word2vec_ko.model\")\n",
    "\n",
    "if not os.path.exists(word2vec_model_path):\n",
    "    raise FileNotFoundError(f\"파일을 찾을 수 없습니다: {word2vec_model_path}\")\n",
    "else:\n",
    "    print(f\"파일을 찾았습니다: {word2vec_model_path}\")\n",
    "\n",
    "word2vec_model = Word2VecKeyedVectors.load(word2vec_model_path)\n",
    "word_vectors = word2vec_model.wv\n",
    "\n",
    "# =============================================================================\n",
    "# 2. pretrained 임베딩 행렬 구성\n",
    "# =============================================================================\n",
    "embedding_dim = word_vectors.vector_size\n",
    "print(\"Word2Vec embedding dimension:\", embedding_dim)\n",
    "\n",
    "vocab_size = 10000\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, idx in word_to_index.items():\n",
    "    if idx >= vocab_size:\n",
    "        continue  # vocab_size 제한 내 단어만 사용\n",
    "    if word == \"<PAD>\":\n",
    "        embedding_matrix[idx] = np.zeros(embedding_dim)\n",
    "    elif word in word_vectors:\n",
    "        embedding_matrix[idx] = word_vectors[word]\n",
    "    else:\n",
    "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
    "\n",
    "# =============================================================================\n",
    "# 3. 데이터 준비: pad_sequences와 라벨 배열 변환\n",
    "# =============================================================================\n",
    "# (partial_x_train, x_val, partial_y_train, y_val, maxlen, word_to_index 등은 이미 정의되었다고 가정)\n",
    "pad_value = word_to_index.get(\"<PAD>\", 0)\n",
    "partial_x_train_padded = pad_sequences(partial_x_train,\n",
    "                                       maxlen=maxlen,\n",
    "                                       padding='post',\n",
    "                                       value=pad_value)\n",
    "x_val_padded = pad_sequences(x_val,\n",
    "                             maxlen=maxlen,\n",
    "                             padding='post',\n",
    "                             value=pad_value)\n",
    "\n",
    "partial_y_train = np.array(partial_y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# =============================================================================\n",
    "# 4. 개선된 모델 구성 (GPU 가속을 위해 LSTM 내부 dropout 제거)\n",
    "# =============================================================================\n",
    "model_improved = Sequential()\n",
    "\n",
    "# pretrained Word2Vec 임베딩 (초기에는 trainable=False로 고정)\n",
    "model_improved.add(Embedding(input_dim=vocab_size,\n",
    "                             output_dim=embedding_dim,\n",
    "                             weights=[embedding_matrix],\n",
    "                             input_length=maxlen,\n",
    "                             trainable=False))\n",
    "model_improved.add(Dropout(0.2))  # 임베딩 후 Dropout 적용\n",
    "\n",
    "# 양방향 LSTM 레이어 1 (내부 dropout 제거하여 cuDNN 사용)\n",
    "model_improved.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model_improved.add(BatchNormalization())\n",
    "model_improved.add(Dropout(0.2))  # 외부 Dropout으로 정규화\n",
    "\n",
    "# 양방향 LSTM 레이어 2 (내부 dropout 제거)\n",
    "model_improved.add(Bidirectional(LSTM(32)))\n",
    "model_improved.add(BatchNormalization())\n",
    "model_improved.add(Dropout(0.2))\n",
    "\n",
    "# 완전 연결(Dense) 레이어\n",
    "model_improved.add(Dense(32, activation='relu'))\n",
    "model_improved.add(BatchNormalization())\n",
    "model_improved.add(Dropout(0.2))\n",
    "\n",
    "# 이진 분류를 위한 출력층 (sigmoid 활성화)\n",
    "model_improved.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_improved.compile(optimizer='adam',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "model_improved.summary()\n",
    "\n",
    "# =============================================================================\n",
    "# 5. 모델 학습 (EarlyStopping 및 ReduceLROnPlateau 콜백 적용)\n",
    "# =============================================================================\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
    "\n",
    "history_improved = model_improved.fit(partial_x_train_padded, partial_y_train,\n",
    "                                      epochs=20,\n",
    "                                      batch_size=512,\n",
    "                                      validation_data=(x_val_padded, y_val),\n",
    "                                      callbacks=[early_stop, lr_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa453739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 정확도: 85.70%\n",
      "검증 정확도가 85% 이상 달성되었습니다!\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가: loss와 accuracy 반환 (여기서 accuracy는 검증 정확도)\n",
    "loss, accuracy = model_improved.evaluate(x_val_padded, y_val, verbose=0)\n",
    "\n",
    "# 검증 정확도 출력 (소수점 두 자리까지 % 표시)\n",
    "print(f\"검증 정확도: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 검증 정확도가 85% 이상인지 확인\n",
    "if accuracy >= 0.85:\n",
    "    print(\"검증 정확도가 85% 이상 달성되었습니다!\")\n",
    "else:\n",
    "    print(\"검증 정확도가 85% 미만입니다!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb92be0c",
   "metadata": {},
   "source": [
    "### word2vec으로 전이학습한 임베딩 차원의 성능 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fc67929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(수동 계산) '사랑'와(과) 유사한 단어:\n",
      "이별: 0.7626\n",
      "행복: 0.7550\n",
      "슬픔: 0.7382\n",
      "유혹: 0.7238\n",
      "그리움: 0.7167\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# '사랑'이라는 단어를 분석 대상으로 지정합니다.\n",
    "target_word = \"사랑\"\n",
    "\n",
    "# 전체 단어 리스트와 벡터를 가져옵니다.\n",
    "all_words = word_vectors.index_to_key  # gensim 버전에 따라 index2word 또는 index_to_key 사용\n",
    "all_vectors = np.array([word_vectors[word] for word in all_words])\n",
    "\n",
    "# '사랑' 단어 벡터 추출\n",
    "target_vector = word_vectors[target_word].reshape(1, -1)\n",
    "\n",
    "# 전체 단어와의 코사인 유사도 계산\n",
    "similarities = cosine_similarity(all_vectors, target_vector).flatten()\n",
    "\n",
    "# 자기 자신은 제외하고 상위 5개 단어 추출\n",
    "top_k = 5\n",
    "sorted_indices = np.argsort(similarities)[::-1]\n",
    "similar_results = []\n",
    "for idx in sorted_indices:\n",
    "    if all_words[idx] == target_word:\n",
    "        continue  # 자기 자신은 제외\n",
    "    similar_results.append((all_words[idx], similarities[idx]))\n",
    "    if len(similar_results) >= top_k:\n",
    "        break\n",
    "\n",
    "print(f\"\\n(수동 계산) '{target_word}'와(과) 유사한 단어:\")\n",
    "for word, sim in similar_results:\n",
    "    print(f\"{word}: {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723c4806",
   "metadata": {},
   "source": [
    "### 회고\n",
    "\n",
    "1. 스스로 작성한 코드가 별로 없는 것 같다. 텐서플로우나 이번에 새로 배운 자연어 처리 관련 라이브러리와 익숙하지 않아서 생긴 문제인 것 같다.\n",
    "2. 그래도 자연어 처리 과정의 전반적인 흐름을 경험해 본 것이라고 생각하고 내용을 추가적으로 더 학습해야겠다는 생각이 들었다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
